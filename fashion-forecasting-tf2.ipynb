{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "793e82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# NOTE: Revisit training loops and adjust for tf.GradientTape if applicable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b597dbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Cami Dresses</th>\n",
       "      <th>Shirts</th>\n",
       "      <th>Tote Bags</th>\n",
       "      <th>Sneakers</th>\n",
       "      <th>Crop Tops</th>\n",
       "      <th>Polos</th>\n",
       "      <th>Cross Body Bags</th>\n",
       "      <th>Casual Jackets</th>\n",
       "      <th>Swimwear</th>\n",
       "      <th>...</th>\n",
       "      <th>Heels</th>\n",
       "      <th>T-Shirts</th>\n",
       "      <th>Activewear Tops &amp; T-Shirts</th>\n",
       "      <th>Watches &amp; Timepieces</th>\n",
       "      <th>Wallets &amp; Card Holders</th>\n",
       "      <th>Bodycon Dresses</th>\n",
       "      <th>Beauty Tools &amp; Accessories</th>\n",
       "      <th>Skinny Jeans</th>\n",
       "      <th>Beauty Eyes</th>\n",
       "      <th>Beauty Face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  Cami Dresses  Shirts  Tote Bags  Sneakers  Crop Tops  Polos  \\\n",
       "0  2017-08-04           0.0     0.0        0.0       0.0        0.0    0.0   \n",
       "1  2017-08-07           0.0     0.0        0.0       0.0        0.0    0.0   \n",
       "2  2017-08-10           0.0     0.0        0.0       0.0        0.0    0.0   \n",
       "3  2017-08-13           0.0     0.0        0.0       0.0        0.0    0.0   \n",
       "4  2017-08-16           0.0     0.0        0.0       0.0        0.0    0.0   \n",
       "\n",
       "   Cross Body Bags  Casual Jackets  Swimwear  ...  Heels  T-Shirts  \\\n",
       "0              0.0             0.0       0.0  ...    1.0       0.0   \n",
       "1              0.0             0.0       0.0  ...    1.0       0.0   \n",
       "2              0.0             0.0       0.0  ...    1.0       0.0   \n",
       "3              0.0             0.0       0.0  ...    1.0       0.0   \n",
       "4              0.0             0.0       0.0  ...    1.0       0.0   \n",
       "\n",
       "   Activewear Tops & T-Shirts  Watches & Timepieces  Wallets & Card Holders  \\\n",
       "0                         0.0                   0.0                     0.0   \n",
       "1                         0.0                   0.0                     0.0   \n",
       "2                         0.0                   0.0                     0.0   \n",
       "3                         0.0                   0.0                     0.0   \n",
       "4                         0.0                   0.0                     0.0   \n",
       "\n",
       "   Bodycon Dresses  Beauty Tools & Accessories  Skinny Jeans  Beauty Eyes  \\\n",
       "0              0.0                         0.0           0.0          0.0   \n",
       "1              0.0                         0.0           0.0          0.0   \n",
       "2              0.0                         0.0           0.0          0.0   \n",
       "3              0.0                         0.0           0.0          0.0   \n",
       "4              0.0                         0.0           0.0          0.0   \n",
       "\n",
       "   Beauty Face  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fashion.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532bcbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "df = df.iloc[:,1:]\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9cfecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "learning_rate = 0.01\n",
    "size_layer = 128\n",
    "timestamp = 5\n",
    "epoch = 500\n",
    "dropout_rate = 0.7\n",
    "future_weeks = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03a0461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, learning_rate, num_layers, size, size_layer, forget_bias=0.8):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.size_layer = size_layer\n",
    "        \n",
    "        # Define LSTM layers\n",
    "        self.lstm_layers = [\n",
    "            tf.keras.layers.LSTM(\n",
    "                units=size_layer,\n",
    "                return_sequences=True if i < num_layers - 1 else False,\n",
    "                return_state=True,\n",
    "                dropout=1 - forget_bias,\n",
    "                recurrent_dropout=1 - forget_bias\n",
    "            )\n",
    "            for i in range(num_layers)\n",
    "        ]\n",
    "        \n",
    "        # Fully connected (dense) layer applied to each time step\n",
    "        self.dense = tf.keras.layers.Dense(\n",
    "            units=size,\n",
    "            kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
    "        )\n",
    "        \n",
    "        # Optimizer\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    def call(self, inputs, initial_states):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        Args:\n",
    "            inputs: Input tensor of shape (batch_size, time_steps, size).\n",
    "            initial_states: List of initial hidden states for LSTM layers.\n",
    "        Returns:\n",
    "            logits: Output predictions from the dense layer.\n",
    "            new_states: Updated hidden states from LSTM layers.\n",
    "        \"\"\"\n",
    "        x = inputs\n",
    "        states = initial_states\n",
    "        new_states = []\n",
    "        \n",
    "        for i, lstm in enumerate(self.lstm_layers):\n",
    "            x, h_state, c_state = lstm(x, initial_state=states[i])\n",
    "            new_states.append([h_state, c_state])\n",
    "        \n",
    "        logits = self.dense(x)  # Dense layer applied to each time step\n",
    "        return logits, new_states\n",
    "\n",
    "    def train_step(self, x, y, initial_states):\n",
    "        \"\"\"\n",
    "        Perform one training step.\n",
    "        Args:\n",
    "            x: Input tensor.\n",
    "            y: Target tensor.\n",
    "            initial_states: List of initial hidden states for LSTM layers.\n",
    "        Returns:\n",
    "            loss: Computed loss for the batch.\n",
    "            new_states: Updated hidden states.\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits, new_states = self.call(x, initial_states)\n",
    "            \n",
    "            # Ensure shapes match by reshaping target if necessary\n",
    "            y = tf.reshape(y, logits.shape)\n",
    "            \n",
    "            loss = self.loss_fn(y, logits)\n",
    "        \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        return loss, new_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5e97cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph resets not needed in TF2.x\n",
    "modelnn = Model(learning_rate, num_layers, df.shape[1], size_layer, dropout_rate)\n",
    "# Initialize model\n",
    "# modelnn = Model(learning_rate, num_layers, size, size_layer, forget_bias)\n",
    "\n",
    "# Dummy data\n",
    "X = tf.random.normal((batch_size, sequence_length, size))\n",
    "Y = tf.random.normal((batch_size, df.shape[1]))\n",
    "\n",
    "# Initial hidden states for each LSTM layer\n",
    "initial_states = [[\n",
    "    tf.zeros((batch_size, size_layer)),\n",
    "    tf.zeros((batch_size, size_layer))\n",
    "] for _ in range(num_layers)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10e1e222",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 450 values, but the requested shape has 45 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(batch_y)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Perform a training step\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m loss, updated_states \u001b[38;5;241m=\u001b[39m \u001b[43mmodelnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Update the initial states with the updated states\u001b[39;00m\n\u001b[0;32m     27\u001b[0m init_value \u001b[38;5;241m=\u001b[39m updated_states\n",
      "Cell \u001b[1;32mIn[21], line 68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, x, y, initial_states)\u001b[0m\n\u001b[0;32m     65\u001b[0m     logits, new_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall(x, initial_states)\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# Ensure shapes match by reshaping target if necessary\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(y, logits)\n\u001b[0;32m     72\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables)\n",
      "File \u001b[1;32md:\\ML\\fashion-trends-pred\\myenv\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32md:\\ML\\fashion-trends-pred\\myenv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\ML\\fashion-trends-pred\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 450 values, but the requested shape has 45 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "# Assuming the `Model` class from earlier and `df` are defined\n",
    "epoch = 1000\n",
    "timestamp = 10\n",
    "batch_size = 1\n",
    "\n",
    "for i in range(epoch):\n",
    "    # Initialize the hidden states for the LSTM layers\n",
    "    init_value = [\n",
    "        [tf.zeros((batch_size, size_layer)), tf.zeros((batch_size, size_layer))]\n",
    "        for _ in range(num_layers)\n",
    "    ]\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for k in range(0, (df.shape[0] // timestamp) * timestamp, timestamp):\n",
    "        # Prepare the batch data\n",
    "        batch_x = np.expand_dims(df.iloc[k: k + timestamp].values, axis=0).astype(np.float32)\n",
    "        batch_y = df.iloc[k + 1: k + timestamp + 1].values.astype(np.float32)\n",
    "\n",
    "        # Convert to tensors\n",
    "        batch_x = tf.convert_to_tensor(batch_x)\n",
    "        batch_y = tf.convert_to_tensor(batch_y)\n",
    "\n",
    "        # Perform a training step\n",
    "        loss, updated_states = modelnn.train_step(batch_x, batch_y, init_value)\n",
    "\n",
    "        # Update the initial states with the updated states\n",
    "        init_value = updated_states\n",
    "        total_loss += loss.numpy()\n",
    "\n",
    "    # Compute average loss for the epoch\n",
    "    total_loss /= (df.shape[0] // timestamp)\n",
    "\n",
    "    # Log progress every 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa1c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_predict = np.zeros((df.shape[0] + future_weeks, df.shape[1]))\n",
    "output_predict[0, :] = df.iloc[0] \n",
    "upper_b = (df.shape[0] // timestamp) * timestamp\n",
    "init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "for k in range(0, (df.shape[0] // timestamp) * timestamp, timestamp):\n",
    "    out_logits, last_state = # Replace sess.run with direct calls or @tf.function in TF2.x([tf.nn.sigmoid(modelnn.logits), modelnn.last_state], \n",
    "                                      feed_dict = {modelnn.X:np.expand_dims(df.iloc[k: k + timestamp], axis = 0),\n",
    "                                     modelnn.hidden_layer: init_value})\n",
    "    init_value = last_state\n",
    "    output_predict[k + 1: k + timestamp + 1] = out_logits\n",
    "    \n",
    "out_logits, last_state = # Replace sess.run with direct calls or @tf.function in TF2.x([tf.nn.sigmoid(modelnn.logits), modelnn.last_state], \n",
    "                                  feed_dict = {modelnn.X:np.expand_dims(df.iloc[upper_b:], axis = 0),\n",
    "                                     modelnn.hidden_layer: init_value})\n",
    "init_value = last_state\n",
    "output_predict[upper_b + 1: df.shape[0] + 1] = out_logits\n",
    "df.loc[df.shape[0]] = out_logits[-1]\n",
    "date_ori.append(date_ori[-1]+timedelta(days=3))\n",
    "\n",
    "# NOTE: Revisit training loops and adjust for tf.GradientTape if applicable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(future_weeks - 1):\n",
    "    out_logits, last_state = # Replace sess.run with direct calls or @tf.function in TF2.x([tf.nn.sigmoid(modelnn.logits), modelnn.last_state], feed_dict = \n",
    "                                      {modelnn.X:np.expand_dims(df.iloc[-timestamp:], axis = 0),\n",
    "                                     modelnn.hidden_layer: init_value})\n",
    "    init_value = last_state\n",
    "    output_predict[df.shape[0], :] = out_logits[-1, :]\n",
    "    df.loc[df.shape[0]] = out_logits[-1, :]\n",
    "    date_ori.append(date_ori[-1]+timedelta(days=3))\n",
    "\n",
    "# NOTE: Revisit training loops and adjust for tf.GradientTape if applicable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ori=pd.Series(date_ori).dt.strftime(date_format='%Y-%m-%d').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = (-np.round(df.values).sum(axis=0)).argsort()[4:10]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a25b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed9218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,15))\n",
    "for no, i in enumerate(index):\n",
    "    plt.subplot(6,1,no+1)\n",
    "    label = list(df)[i]\n",
    "    plt.plot(np.around(df.iloc[:,i]),label='predicted ' + label,alpha=0.7)\n",
    "    plt.plot(np.around(df_copy.iloc[:,i]),label='real ' + label,alpha=0.7)\n",
    "    plt.legend()\n",
    "    x_range_future = np.arange(df.shape[0])\n",
    "    plt.xticks(x_range_future[::20], date_ori[::20])\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a7618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_shift(df,lag=0,rejected_columns = []):\n",
    "    df = df.copy()\n",
    "    if not lag:\n",
    "        return df\n",
    "    cols ={}\n",
    "    for i in range(1,lag+1):\n",
    "        for x in list(df.columns):\n",
    "            if x not in rejected_columns:\n",
    "                if not x in cols:\n",
    "                    cols[x] = ['{}_{}'.format(x, i)]\n",
    "                else:\n",
    "                    cols[x].append('{}_{}'.format(x, i))\n",
    "    for k,v in cols.items():\n",
    "        columns = v\n",
    "        dfn = pd.DataFrame(data=None, columns=columns, index=df.index)    \n",
    "        i = 1\n",
    "        for c in columns:\n",
    "            dfn[c] = df[k].shift(periods=i)\n",
    "            i+=1\n",
    "        df = pd.concat([df, dfn], axis=1, join_axes=[df.index])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_shift(df, 2)\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6547932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6105d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title('2 days correlation', y=1.05, size=16)\n",
    "\n",
    "mask = np.zeros_like(df_new.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "sns.heatmap(df_new.corr(), mask=mask, linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap=colormap, linecolor='white', annot=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9751497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
